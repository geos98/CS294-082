{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment \n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pytorch_resnet_cifar10' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Clone the ResNet implementation we are going to use\n",
    "# Clone the ResNet implementation we are going to use\n",
    "!git clone https://github.com/geos98/CS294-082.git\n",
    "%cd CS294-082\n",
    "!git clone https://github.com/akamaster/pytorch_resnet_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_resnet_cifar10.resnet import resnet20\n",
    "\n",
    "state_dict_path = 'resnet_20_pretrain.pt'\n",
    "state_dict = torch.load(state_dict_path, map_location=device)\n",
    "\n",
    "model = resnet20()\n",
    "miss = model.load_state_dict(state_dict)\n",
    "\n",
    "print(miss)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, 4),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "\n",
    "# Train data with test set trainsform (i.e., no crop, no flip)\n",
    "traintestset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=test_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=128, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(testset, batch_size=128, shuffle=False, pin_memory=True)\n",
    "traintest_loader = DataLoader(traintestset, batch_size=128, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:16<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set: Predicted 9177 instances out of 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [01:22<00:00,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning Set: Predicted 49861 instances out of 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on accuracy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    # Accuracy on test set\n",
    "    for p, l in tqdm(test_loader):\n",
    "        p = p.to(device)\n",
    "        out = model(p)\n",
    "        _, predicted = out.max(1)\n",
    "\n",
    "        correct_test += predicted.eq(l).sum().item()\n",
    "        total_test += l.size(0)\n",
    "    print('Testing Set: Predicted {} instances out of {}'.format(correct_test, total_test))\n",
    "\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    # Accuracy on test set\n",
    "    for p, l in tqdm(traintest_loader):\n",
    "        p = p.to(device)\n",
    "        out = model(p)\n",
    "        _, predicted = out.max(1)\n",
    "\n",
    "        correct_train += predicted.eq(l).sum().item()\n",
    "        total_train += l.size(0)\n",
    "    print('Trainning Set: Predicted {} instances out of {}'.format(correct_train, total_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: What is the variable the machine learner is supposed to predict? How accurate is the labeling? What is the annotator agreement (measured)?\n",
    "The CIFAR-10 dataset consists of 60,000 images of 10 classes which are  `airplane`, `automobile`, `bird`, `cat`, `deer`, `dog`, `frog`, `horse`, `ship` and `truck`. The machine learner should take-in an image and predict what is the object in the image by outputing one of the 10 classes listed above.\n",
    "\n",
    "There are a total of 22 known and validated label error exists in this dataset[1]. The label error was found algorithmically and further verified by human. This is 99.96% label accuracy. For the purpose of this project, we will ignore this error and assume the labelling is correct. \n",
    "\n",
    "Researchers at the University of Toronto paid human labler to label the dataset[2]. Each labelling is done by one human labler and verified by the one of the researchers after initial labelling. The in-accuracy could be caused by human error due to the large workload needed to label this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: What is the required accuracy metric for success? How much data do we have to train the prediction of the variable? Are the classes balanced? How many modalities could be exploited in the data? Is there temporal information? How much noise are we expecting? Do we expect bias?\n",
    "\n",
    "Since this dataset serves as a benchmark towards the machine learner's ability to classify subjects in the image, the required accuracy metric is higher the better. However, there were no real-world implication for the success at this time.\n",
    "\n",
    "We have 60,000 images, splited into a trainning set of 50,000 images and testing set of 10,000 images. \n",
    "\n",
    "The classes are perfectly balanced in both trainning set and testing set. Meaning that in total there are 6,000 images of each class.\n",
    "\n",
    "There is only one modality, the visual, that we can exploit. \n",
    "\n",
    "There are no temporal information. \n",
    "\n",
    "Since every sample is an image with a background, and we are only interested in the main subject, this means that all the background portion of the image is effectively noise for our purpose. Therefore, we need to apply strategies like convolution to extract important features.\n",
    "\n",
    "We expect the machine learner to focus on the center of the image since that is the place where most subject would exists in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: What is the MEC of the data? What is the expected MEC for a neural net?\n",
    "\n",
    "Since we only care about the MEC of the data after the \"compression\", we will create a CSV file of data after compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [03:27<00:00, 288.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate .csv from pre-trained ResNet-18 (only using the conv layer to extract deepfeature)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "# Get pre-trained conv output\n",
    "def run_conv(x):\n",
    "    out = F.relu(model.bn1(model.conv1(x)))\n",
    "    out = model.layer1(out)\n",
    "    out = model.layer2(out)\n",
    "    out = model.layer3(out)\n",
    "    out = F.avg_pool2d(out, out.size()[3])\n",
    "    out = out.view(out.size(0), -1)\n",
    "\n",
    "    return out\n",
    "\n",
    "with open('compressed.csv', 'w+') as fout:\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_len = len(traintestset) + len(testset)\n",
    "        for p, l in tqdm(chain(traintestset, testset), total = total_len):\n",
    "            p = torch.unsqueeze(p, 0).to(device)\n",
    "            conv_data = run_conv(p)\n",
    "            np_data = conv_data.flatten().cpu().numpy()\n",
    "            CSV_str = ','.join(['%.15f' % num for num in np_data])\n",
    "            CSV_str += ',{}'.format(l)\n",
    "            fout.write(CSV_str + '\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either run Brainome on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Brainome for analysis\n",
    "#%pip install brainome\n",
    "#!brainome login\n",
    "#!brainome compressed.csv -y -headerless -f NN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can run our own analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.632485</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.542533</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.231566</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.198811</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.481588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49.246642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59.517407</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49.590992</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46.345304</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50.236550</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sum  label\n",
       "0  43.632485      6\n",
       "1  65.542533      9\n",
       "2  51.231566      9\n",
       "3  40.198811      4\n",
       "4  58.481588      1\n",
       "5  49.246642      1\n",
       "6  59.517407      2\n",
       "7  49.590992      7\n",
       "8  46.345304      8\n",
       "9  50.236550      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Threshold =  54082\n",
      "MEC =  1038.7105789672364  bits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Implement Alogrithm 2 in the book\n",
    "df = pd.read_csv('compressed.csv', header=None)\n",
    "dim = df.shape[1] - 1\n",
    "\n",
    "df = pd.DataFrame({'sum': df.iloc[:, :-1].sum(axis = 1), 'label': df.iloc[:, 64]})\n",
    "\n",
    "# Drop the raw pixels\n",
    "df.sort_values('sum')\n",
    "display(df.head(10))\n",
    "\n",
    "thr = (df['label'].diff() != 0).sum()\n",
    "print('Total Threshold = ', thr)\n",
    "\n",
    "min_thr = math.log2(thr + 1)\n",
    "mec = (min_thr * (dim + 1)) + (min_thr + 1)\n",
    "print('MEC = ', mec, ' bits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As calculated above, we find that the MEC of the data is around 1038.7 bits.\n",
    "\n",
    "\n",
    "The decision layer in ResNet-20 is a simple fully connected layer with 64 input and 10 output. That is, 10 neurons each with 64 input.Now, each individual neuron therefore have parameter count of 64 + 1 = 65 and the MEC of the network is  \n",
    "65 * 10 = 650 bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: What is the expected generalization in bits/bit and as a consequence the average resilience in dB? Is the resilience enough for the task? How bad can adversarial examples be? Do we expect data drift?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:00<00:00, 70162.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicted instances:  59038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the data on pre-trained decision layer\n",
    "from torch.utils.data.dataset import Dataset\n",
    "class CompressedCifar10(Dataset):\n",
    "    def __init__(self):\n",
    "        df = pd.read_csv('compressed.csv', header=None)\n",
    "\n",
    "        x = df.iloc[:, 0:64].values\n",
    "        y = df.iloc[:, 64].values\n",
    "\n",
    "        self.x_data = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "        self.y_data = torch.tensor(y, dtype=torch.int32, device=device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "total_correct = 0\n",
    "with torch.no_grad():\n",
    "    dataset = CompressedCifar10()\n",
    "\n",
    "    for x, y in tqdm(dataset):\n",
    "        preidct = model.linear(x)\n",
    "        predict = torch.argmax(preidct)\n",
    "\n",
    "        if predict == y:\n",
    "            total_correct += 1\n",
    "\n",
    "print('Correctly predicted instances: ', total_correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, combine MEC = 650 bit, we get the Generalization is\n",
    "\n",
    "$$G = \\frac{59038  \\log_2{10}}{MEC} = 188.81 \\frac{\\text{bits}}{\\text{bit}}$$\n",
    "\n",
    "Which would then traslate to resilience $R = 20 * \\log_{10}G = 20 * \\log_{10} 188.81 = 45.52 \\text{dB}$\n",
    "\n",
    "Since this is a benchmark for machine learning models, we don't expect adversarial examples nor do we expect data drift. The data is as-is, nothing new would be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "[1] https://arxiv.org/abs/2103.14749  \n",
    "[2] https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
